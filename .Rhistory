## Global Variables
### The name of the site you are searchng for (no spaces)
sitename: "Agnew_State_Forest"
## Global Variables
### The name of the site you are searchng for (no spaces)
sitename --> "Agnew_State_Forest"
## ------------------------------ Work Space -----------------------------------
## Global Variables
### The name of the site you are searching for
sitename: "Agnew_State_Forest"
## ------------------------------ Work Space -----------------------------------
## Global Variables
### The name of the site you are searching for
sitename= "Agnew_State_Forest"
## ---------------------------- Function Code ----------------------------------
## Start of function code
woodlandweather <- function() {
cat(paste(sitename, "|", site_latitude, ", ", site_longitude, "\n"))
}
woodlandweather()
site_latitude = 40
site_longitude = -75
woodlandweather()
### Disclaimer: To search by specific variable range view "StationData.csv".
## -----------------------------------------------------------------------------
## ---------------------------- Function Code ----------------------------------
## Start of function code
woodlandweather <- function() {
## Extract data from NOAA and build "StationData" Data Frame
## This will take approximately [X] minutes your first run through
data_folder <- "station_data_temp"  ## name of temporary data folder
# Check if the data folder exists
if (!dir.exists(data_folder)) {
# If it doesn't exist, create the folder and download the files
dir.create(data_folder)
# Define the URL of the NOAA Weather Station Monthly Repoorts
noaa_data_url <- "https://www.ncei.noaa.gov/data/global-summary-of-the-month/access/"
# Function to download and save the files
download_and_save_file <- function(url, folder) {
filename <- basename(url)
destination <- file.path(folder, filename)
download.file(url, destfile = destination, mode = "wb")
}
# Extract the links to CSV files from the web page
page <- readLines(noaa_data_url)
links <- page[grep(".csv", page)]
# Download and save each CSV file
for (link in links) {
full_url <- paste0(noaa_data_url, link)
download_and_save_file(full_url, data_folder)
}
cat("station_data_temp created and files downloaded.\n")
} else {
cat("station_data_temp found.\n")
}
}
woodlandweather()
}}
woodlandweather()
### Disclaimer: To search by specific variable range view "StationData.csv".
## -----------------------------------------------------------------------------
## ---------------------------- Function Code ----------------------------------
## Start of function code
woodlandweather <- function() {
## Extract data from NOAA and build "StationData" Data Frame
## This will take approximately [X] minutes your first run through
data_folder <- "station_data_temp"  ## name of temporary data folder
# Check if the data folder exists
if (!dir.exists(data_folder)) {
# If it doesn't exist, create the folder and download the files
dir.create(data_folder)
# Define the URL of the NOAA Weather Station Monthly Repoorts
noaa_data_url <- "https://www.ncei.noaa.gov/data/global-summary-of-the-month/access/"
# Function to download and save the files
download_and_save_file <- function(url, folder) {
filename <- basename(url)
destination <- file.path(folder, filename)
download.file(url, destfile = destination, mode = "wb")
}
# Extract the links to CSV files from the web page
page <- readLines(noaa_data_url)
links <- page[grep(".csv", page)]
# Download and save each CSV file
for (link in links) {
full_url <- paste0(noaa_data_url, link)
download_and_save_file(full_url, data_folder)
}
cat("station_data_temp created and files downloaded.\n")
} else {
cat("station_data_temp found.\n")
}
}
woodlandweather()
### Disclaimer: To search by specific variable range view "StationData.csv".
## -----------------------------------------------------------------------------
## ---------------------------- Function Code ----------------------------------
## Start of function code
woodlandweather <- function() {
## Extract data from NOAA and build "StationData" Data Frame
## This will take approximately [X] minutes your first run through
data_folder <- "station_data_temp"  ## name of temporary data folder
# Check if the data folder exists
if (!dir.exists(data_folder)) {
# If it doesn't exist, create the folder and download the files
dir.create(data_folder)
# Define the URL of the NOAA Weather Station Monthly Repoorts
noaa_data_url <- "https://www.ncei.noaa.gov/data/global-summary-of-the-month/access/"
# Function to download and save a file
download_and_save_file <- function(url, folder) {
filename <- basename(url)
destination <- file.path(folder, filename)
download.file(url, destfile = destination, mode = "wb")
}
# Extract the links to CSV files from the web page
page <- readLines(noaa_data_url)
links <- page[grep("US.*\\.csv", page)]
# Download and save each CSV file
for (link in links) {
full_url <- paste0(noaa_data_url, link)
download_and_save_file(full_url, data_folder)
}
# Download and save each CSV file
for (link in links) {
full_url <- paste0(noaa_data_url, link)
download_and_save_file(full_url, data_folder)
}
cat("station_data_temp created and files downloaded.\n")
} else {
cat("station_data_temp found.\n")
}
}
woodlandweather()
woodlandweather()
### Necessary Libraries
library(rvest)
### Disclaimer: To search by specific variable range view "StationData.csv".
## -----------------------------------------------------------------------------
## ---------------------------- Function Code ----------------------------------
## Start of function code
woodlandweather <- function() {
data_folder <- "station_data_temp"  ## Name of the temporary data folder
# Check if the data folder exists
if (!dir.exists(data_folder)) {
# If it doesn't exist, create the folder and download the files
dir.create(data_folder)
# Define the URL of the NOAA Weather Station Monthly Reports
noaa_data_url <- "https://www.ncei.noaa.gov/data/global-summary-of-the-month/access/"
# Function to download and save a file
download_and_save_file <- function(url, folder) {
filename <- basename(url)
destination <- file.path(folder, filename)
download.file(url, destfile = destination, mode = "wb")
}
# Fetch the webpage and extract links to CSV files
page <- read_html(noaa_data_url)
links <- page %>%
html_nodes("a[href^='US'][href$='.csv']") %>%
html_attr("href")
# Download and save each CSV file
for (link in links) {
full_url <- paste0(noaa_data_url, link)
download_and_save_file(full_url, data_folder)
}
cat("station_data_temp created and files downloaded.\n")
} else {
cat("station_data_temp found.\n")
}
}
esc
### Disclaimer: To search by specific variable range view "StationData.csv".
## -----------------------------------------------------------------------------
## ---------------------------- Function Code ----------------------------------
## Start of function code
woodlandweather <- function() {
data_folder <- "station_data_temp"  ## Name of the temporary data folder
# Check if the data folder exists
if (!dir.exists(data_folder)) {
# If it doesn't exist, create the folder and download the files
dir.create(data_folder)
# Define the URL of the NOAA Weather Station Monthly Reports
noaa_data_url <- "https://www.ncei.noaa.gov/data/global-summary-of-the-month/access/"
# Function to download and save a file
download_and_save_file <- function(url, folder) {
filename <- basename(url)
destination <- file.path(folder, filename)
download.file(url, destfile = destination, mode = "wb")
}
# Fetch the webpage and extract links to CSV files
page <- read_html(noaa_data_url)
links <- page %>%
html_nodes("a[href^='US'][href$='.csv']") %>%
html_attr("href")
# Download and save each CSV file
for (link in links) {
full_url <- paste0(noaa_data_url, link)
download_and_save_file(full_url, data_folder)
}
cat("station_data_temp created and files downloaded.\n")
} else {
cat("station_data_temp found.\n")
}
}
